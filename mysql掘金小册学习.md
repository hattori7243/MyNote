### 安装目录下的可执行文件

mysql在我电脑上的安装目录:`/usr/local/Cellar/mysql/8.0.22_1`。

`./bin`目录下的文件

- `mysqld`，启动mysql服务器程序。不常用，直接启动一个服务器进程
- `mysqld_safe`：启动脚本，会间接调用`mysqld`，而且会启动一个监控进程，在服务器进程挂了的时候，帮助重启。
- `mysql.server`：启动脚本，会间接调用`mysql_safe`。
  - 启动 `mysql.server start`
  - 关闭 `mysql.server stop`
- `mysql`。启动客户端程序来连接到服务器
  - `-h 主机名 -u用户名 -p密码`
  - 同一账号可以开启多个客户端程序，客户端程序互不影响

# 客户端和服务器连接的过程

支持三种客户端进程和服务器进程的通信方式

### 1. TCP/IP

真实环境中，服务器和客户端可能存在不同的主机中，必须通过网络来通讯。在网络中通过ip+端口来进行连接。

- **mysql服务器启动时默认申请3306端口号**，然后监听该端口号，等待客户端进行连接。
  - 如果端口号3306被占用，可以在启动服务器进程时`mysqld -P3307`来指定端口号
  - 客户端连接的时候也可以`-P`指定端口号，注意-p后面是密码，-P后面是端口号

### 2. 命名管道和共享内存

只能在服务器和客户端进程在同一台windows主机中时使用

### 3. Unix域套接字文件

服务器进程和客户端进程都运行在同一台操作系统为类`Unix`的机器上时可以使用。

服务器程序默认监听的`Unix`域套接字文件路径是`/tmp/mysql.sock`

- 可以在启动服务器时指定socket参数，但是此时客户端启动时也要显式指定
  - `mysqld --socket=/tmp/a,txt`
  - `mysql -hlocalhost -uroot --socket=/tmp/a.txt -p`

# 服务器处理客户端的请求

![](https://raw.githubusercontent.com/hattori7243/img/master/20210531105145.png)

### 1. 连接管理

- 每当有一个客户端进程连接到服务器进程时，服务器进程都会创建一个线程来专门处理与这个客户端的交互。

- 当该客户端退出时会与服务器断开连接，**服务器并不会立即把与该客户端交互的线程销毁掉，而是把它缓存起来**。
- 在另一个新的客户端再进行连接时，**把这个缓存的线程分配给该新客户端**。
- 这样就起到了**不频繁创建和销毁线程的效果，从而节省开销**

### 2. 解析与优化

#### 查询缓存

会把刚刚处理过的查询请求和结果**缓存**起来。查询缓存在**不同客户端**之间共享

涉及一些系统函数、用户自定义变量和函数的，不会被缓存。例如与系统函数时间有关的。

当表的结构被修改，使用该表的缓存就会被无效。

- 缓存虽然有时可以提升性能，但维护也需要很大的开销。从`mysql5.7.20`开始，不推荐使用查询缓存，并在`mysql8.0`中被删除。
  - 现在缓存多用redis做
  - 而且现在基本都是数据密集应用，数据经常变动，缓存经常失效，管理开销大

#### 语法解析

将文本解析，类似于编译工作，涉及词法解析、语法分析、语义分析等

#### 查询优化

对给出的语句做一些优化

可以用explain语句来查看某个语句的执行计划

### 3. 存储引擎

接受上层传下来的命令，然后对表中的数据进行提取或者写入操作。

即在`mysql server`完成了查询优化后，调用底层存储引擎提供的api获取到数据后，返回个客户端

**mysql支持的存储引擎**：

| 存储引擎    | 描述                                 |
| ----------- | ------------------------------------ |
| `ARCHIVE`   | 用于数据存档（行被插入后不能再修改） |
| `BLACKHOLE` | 丢弃写操作，读操作会返回空内容       |
| `CSV`       | 在存储数据时，以逗号分隔各个数据项   |
| `FEDERATED` | 用来访问远程表                       |
| `InnoDB`    | 具备外键支持功能的事务存储引擎       |
| `MEMORY`    | 置于内存的表                         |
| `MERGE`     | 用来管理多个MyISAM表构成的表集合     |
| `MyISAM`    | 主要的非事务处理存储引擎             |
| `NDB`       | MySQL集群专用存储引擎                |

最常用的是**InnoDB**和**MyISAM**。其中**InnoDB**是默认存储引擎

可以在创建表的时候指定存储引擎，也可以修改某个表的存储引擎

### Mysql的启动选项和配置文件

针对系统变量和配置文件优先级：  

1. 命令行优先级高于文件优先级  

2. 多个my.cnf配置文件，以最后一个为准 

3. 同一个my.cnf配置文件，在继承组里面以最后一个为准

系统变量和状态变量，有作用域一说，  针对全局使用GLOBAL,针对会话使用SESSION

- 以`default_storage_engine`举例，在服务器启动时会初始化一个名为`default_storage_engine`，作用范围为`GLOBAL`的系统变量。之后每当有一个客户端连接到该服务器时，服务器都会单独为该客户端分配一个名为`default_storage_engine`，作用范围为`SESSION`的系统变量，该作用范围为`SESSION`的系统变量值按照当前作用范围为`GLOBAL`的同名系统变量值进行初始化。

---

## Mysql字符集

正常的utf8字符集表示一个字符需要1-4字节。采用变长编码。

在mysql中，utf8是utf8mb3的别名。

- `utf8mb3`:阉割过的utf8字符集，只使用1-3个字节表示字符
- `utf8mb4`：正宗的utf8字符集，使用1-4字节表示字符

#### 各级别的字符集和比较规则

`Mysql`有4个级别的字符集比较规则，分别是

- 服务器级别
- 数据库级别
- 表级别
- 列级别

MySQL字符集具有继承属性，server级别-database级别-table级别-column级别。如果新建时未指定字符集，那么默认继承上一级的编码。 

#### 客户端和服务器通信中的字符集

| 系统变量                   | 描述                                                         |
| -------------------------- | ------------------------------------------------------------ |
| `character_set_client`     | 服务器解码请求时使用的字符集                                 |
| `character_set_connection` | 服务器处理请求时会把请求字符串从`character_set_client`转为`character_set_connection` |
| `character_set_results`    | 服务器向客户端返回数据时使用的字符集                         |

通过`SET NAMES 字符集名;`可以设置字符集，等价于

```
SET character_set_client = 字符集名;
SET character_set_connection = 字符集名;
SET character_set_results = 字符集名;
```



![](https://raw.githubusercontent.com/hattori7243/img/master/20210531152432.png)

# InnoDB存储结构

**InnoDB是Mysql默认的存储引擎**

数据是存到磁盘上的。但是处理数据的过程是发生在内存中的，所以需要将磁盘中的数据加载到内存中。

因此，将数据划分为若干页，以页作为和内存交互的基本单位，减少IO次数。

**InnoDB中页大小一般为16KB**

## InnoDB行格式

我们平时是以记录为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为`行格式`或者`记录格式`。可以在创建或者修改表的时候，指定行格式。

```
CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称

ALTER TABLE 表名 ROW_FORMAT=行格式名称
```

设计`InnoDB`存储引擎的大叔们到现在为止设计了4种不同类型的`行格式`，分别是

#### 1. `Compact`行格式

<img src="https://raw.githubusercontent.com/hattori7243/img/master/20210531160600.png" style="zoom:80%;" />

- **变长字段长度列表**：**变长字段**中存储多少字节的数据是不固定的，所以我们在存储真实数据的时候需要存储数据占用的字节数
  - 在`Compact`行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表，各变长字段数据占用的字节数按照列的顺序**逆序存放**
  - 只存储值为 ***非NULL*** 的列内容占用的长度
  - 如果表中所有的列 都不是变长数据类型的话，就没有这部分
  - 需要注意的是，哪怕列的定义不是变长的，但是字符集采用的是变长的编码，也是属于变长字段
- **NULL值列表**：所以`Compact`行格式把这些值为`NULL`的列统一管理起来，存储到`NULL`值列表中
  - 先统计表中允许存NULL的列有哪些，然后用一个位图来表示，每一个bit表示该列在该记录下是不是null。1是0不是。注意同样是**逆序**
  - 会在高位补0进行字节对齐
  - <img src="https://raw.githubusercontent.com/hattori7243/img/master/20210531161256.png" style="zoom:70%;" />

- **记录头信息**：固定5个字节。一个用于描述记录本身的头信息
  - `delete_mask`：删除标记，标记当前记录被删除。因为如果真的删除，重新排列记录需要消耗性能。所有被删除掉的记录都会组成一个所谓的`垃圾链表`，在这个链表中的记录占用的空间称之为所谓的`可重用空间`，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。
  - `next_record`：当前记录的真实数据到下一条记录的真实数据的地址偏移量。下一条数据指的并不是插入顺序，而是主键由小到大。类似链表链起来了。
- **记录的真实数据**：
  - 隐藏列：
    - DB_ROW:当用户没有定义主键时，会选取一个Unique的键作为主键。如果也没有Unique的键，会自动生成一个名字为DB_ROW的列作为主键来唯一表示一条记录，占6个字节
    - DB_TRX_ID：6个字节，事务ID，自动生成
    - DB_ROLL_PTR：7个字节，回滚指针，自动生成
  - 行溢出：如果列数据太多，只会保存768字节的一部分，其他放在别的页中，并用20字节的指针指向。

![](https://raw.githubusercontent.com/hattori7243/img/master/20210531163137.png)

**示意图**

![](https://raw.githubusercontent.com/hattori7243/img/master/20210531161849.png)

#### 2. `Redundant`行格式

是`MySQL5.0`之前用的一种行格式

<img src="https://raw.githubusercontent.com/hattori7243/img/master/20210531162132.png" style="zoom:80%;" />

在字段长度偏移列表中，不仅标示了每个列实际的长度，还用1bit来表示了是不是为空

#### 3. `Dynamic`行格式

和Compact类似，只不过在溢出时，不会存储真实的前768字字节，而是全部都存到别的页中，只保存一个指针

#### 4. `Compressed`行格式

会采用压缩算法对页面进行压缩，以节省空间

## InnoDB数据页结构

<img src="https://raw.githubusercontent.com/hattori7243/img/master/20210531164101.png" style="zoom:50%;" />

| 名称                 | 中文名             | 占用空间大小 | 简单描述                 |
| -------------------- | ------------------ | ------------ | ------------------------ |
| `File Header`        | 文件头部           | `38`字节     | 页的一些通用信息         |
| `Page Header`        | 页面头部           | `56`字节     | 数据页专有的一些信息     |
| `Infimum + Supremum` | 最小记录和最大记录 | `26`字节     | 两个虚拟的行记录         |
| `User Records`       | 用户记录           | 不确定       | 实际存储的行记录内容     |
| `Free Space`         | 空闲空间           | 不确定       | 页中尚未使用的空间       |
| `Page Directory`     | 页面目录           | 不确定       | 页中的某些记录的相对位置 |
| `File Trailer`       | 文件尾部           | `8`字节      | 校验页是否完整           |

- 存储的记录会按照我们指定的`行格式`存储到`User Records`部分。每当我们插入一条记录，都会从`Free Space`部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到`User Records`部分，当`Free Space`部分的空间全部被`User Records`部分替代掉之后，也就意味着这个页使用完了，需要申请新的页。
- 会根据主键维护一条主键值从小到大的单链表。Infrmum恒定为起点，supremum恒定为重点。
- `Page Directory`:页目录，会将全部页面按照主键大小，分成好几组。最大的作为组长，标记着当前组有多少个记录。然后目录中保存到每一组组长的偏移量。这样就可以用二分法来查找到组长，然后去组长的链中顺序查找。
- `Page Header`；数据页面头部，存储着当前页的数据的状态信息，比如存储了多少条记录，第一条记录的地址在哪，有多少个槽等等

- `File Header`：文件头部，针对各种类型的页的信息，比如当前页的编号，上一个页是谁，下一个页是谁等等
- `File Tailer`：所有页通用，用来校验当前页是否出错

# B+树索引

![](https://raw.githubusercontent.com/hattori7243/img/master/20210602185005.png)

`目录项记录`和普通的`用户记录`的不同点：

- `目录项记录`的`record_type`值是1，而普通用户记录的`record_type`值是0。
- `目录项记录`只有主键值和页的编号两个列，而普通的用户记录的列是用户自己定义的，可能包含很多列，另外还有`InnoDB`自己添加的隐藏列。
- 还记得我们之前在唠叨记录头信息的时候说过一个叫`min_rec_mask`的属性么，只有在存储`目录项记录`的页中的主键值最小的`目录项记录`的`min_rec_mask`值为`1`，其他别的记录的`min_rec_mask`值都是`0`。

一般情况下，我们用到的`B+`树都不会超过4层，那我们通过主键值去查找某条记录最多只需要做4个页面内的查找（查找3个目录项页和一个用户记录页），又因为在每个页面内有所谓的`Page Directory`（页目录），所以在页面内也可以通过二分法实现快速定位记录

需要注意的是，B+树是从上往下分裂生长的，也就是说根页面是不变的，这也方便要用这个索引时能很方便的找到根结点

**聚簇索引**

- 使用记录的主键值大小进行记录和页的排序
- 叶子节点存储的是完整的用户记录

如果查找的是非主键的话，就可以去查找到非主键的索引树。但是其中只会包括该键和主键。并没有完整的记录。所以仍然需要根据查询到的主键去主键的索引中再查一遍。这个过程称为**回表**。这种针对非主键建立的索引也叫做**二级索引**或者**辅助索引**

- 因为回表操作查找到的主键是无序的，所以速度慢。所以如果二级索引+回表次数过多，性能可能还不如不用索引直接全局扫描。这由查询优化器分析决定。
- 因此，为了减少回表操作，如果不是必要的话，少用*。而是在查询列表中只包含索引列。这样就不用回表

为了保障二级索引的唯一性，避免出现当该列属性值相同时不知道插到哪个页面中的情况，二级索引中不仅包含着当前的键和页号，还包括主键，这样这个三元组就是唯一的，避免歧义。

- InnoDB存储引擎会自动的为主键建立B+树索引，但是如果需要对其他的列建立索引就需要显示的指明。

**创建表时**

```
CREATE TALBE 表名 (
    各种列的信息 ··· , 
    [KEY|INDEX] 索引名 (需要被索引的单个列或多个列)
)
```

**修改表结构**

```
添加索引 ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列);

删除索引 ALTER TABLE 表名 DROP [INDEX|KEY] 索引名;
```

### B+树索引适用的条件

如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。

比方说联合索引`idx_name_birthday_phone_number`中列的定义顺序是`name`、`birthday`、`phone_number`，如果我们的搜索条件中只有`name`和`phone_number`，而没有中间的`birthday`，比方说这样：

```
SELECT * FROM person_info WHERE name = 'Ashburn' AND phone_number = '15123983239';
```

这样只能用到`name`列的索引，`birthday`和`phone_number`的索引就用不上了，因为`name`值相同的记录先按照`birthday`的值进行排序，`birthday`值相同的记录才按照`phone_number`值进行排序。

### 如何挑选索引

- 只为搜索、排序或分组的列创建索引
- 考虑列的基数
  - 即列的取值个数，如果重复度太高，索引排序的效果就差
  - 最好为那些列的基数大的列建立索引
- 索引列的类型尽量小
  - 我们能使用`INT`就不要使用`BIGINT`，能使用`MEDIUMINT`就不要使用`INT`
  - 节省更多存储空间和更高效的IO
- 索引字符串值的前缀
  - `B+`树索引中的记录需要把该列的完整字符串存储起来，而且字符串越长，在索引中占用的存储空间越大。
  - 如果`B+`树索引中索引列存储的字符串很长，那在做字符串比较时会占用更多的时间。
  - 只在`B+`树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，还大概能解决排序的问题
- 为了尽可能少的让`聚簇索引`发生页面分裂和记录移位的情况，建议让主键拥有`AUTO_INCREMENT`属性。

# MySql的数据目录

MySQL服务器程序在启动时会到文件系统的某个目录下加载一些文件，之后在运行过程中产生的数据也都会存储到这个目录下的某些文件中，这个目录就称为`数据目录`

- 当创建database的时候，会在数据目录下创建一个相应的文件夹
- 创建表时，会在该文件夹下创建对应描述表和存储数据的文件

## 如何存储表数据？

使用页为基本单位进行存储。通过表空间的概念，对应文件系统上一个或者多个真实文件，每个表空间可以被划分成很多页，表数据就存在某个表空间的某些页里。

### InnoDB

#### 1. 系统表空间

默认情况下，是数据目录下名为`ibdata1`的文件，默认是12M，会自动增加文件大小。

具体可以在mysql启动时设置对应的文件路径和大小。

mysql只有在5.5.7版本到5.6.6版本时，表中的数据都会被默认存在这个系统表空间

在mysql 8.0以后没有描述表结构的.frm文件了，元数据都存在系统表空间里。

#### 2. 独立表空间

在MySQL5.6.6以及之后的版本中，`InnoDB`并不会默认的把各个表的数据存储到系统表空间中，而是为**每一个表**建立一个独立表空间

**文件名与表名相同，后缀为ibd**

在启动mysql的时候可以自己指定使用系统表空间还是独立表空间

### MyISAM

因为MyISAM的索引和数据是分开的，索引全是二级索引。所以在文件系统中使用不同的文件来存储，全部是是存在数据库对应的目录下。

```
test.frm
test.MYD
test.MYI
```

其中`test.MYD`代表表的数据文件，也就是我们插入的用户记录；`test.MYI`代表表的索引文件，我们为该表创建的索引都会放到这个文件中。

## Mysql系统数据库

有几个系统数据库是默认都会创建的

<img src="https://raw.githubusercontent.com/hattori7243/img/master/20210604203240.png" style="zoom:50%;" />

- mysql

存储了用户账户和权限信息

- information_schema

这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。

- performance_schema

这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息。

- sys

这个数据库主要是通过视图的形式把`information_schema`和`performance_schema`结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。

# InnoDB的表空间

- 在页的头部中的`FIL_PAGE_OFFSET`字段是页号，大小为4字节，也就是说一个表空间最多可以拥有2<sup>32</sup>个个页。因此按照一个页默认16KB的话，一个表空间大小最多为2<sup>32+14</sup>=64TB的数据

## 独立表空间

### 区、组、段的概念

- 区：表空间中连续的64个页就是一个区。也就一个区默认=64*16KB=1MB。在物理空间上也连续。

- 组：256个区划分成一个组，一个组默认=256MB

第一个组最开始的第一个区的三个页面的类型是固定的。其余组的最开始两个页面类型是固定的。

- 第一个组最开始的3个页面的类型是固定的，也就是说`extent 0`这个区最开始的3个页面的类型是固定的，分别是：
  - `FSP_HDR`类型：这个类型的页面是用来登记整个表空间的一些整体属性以及本组所有的`区`，也就是`extent 0` ~ `extent 255`这256个区的属性，稍后详细唠叨。需要注意的一点是，**整个表空间只有一个`FSP_HDR`类型的页面。**
  - `IBUF_BITMAP`类型：这个类型的页面是存储本组所有的区的所有页面关于`INSERT BUFFER`的信息。
  - `INODE`类型：这个类型的页面存储了许多称为`INODE`的数据结构。
- 其余各组最开始的2个页面的类型是固定的，也就是说`extent 256`、`extent 512`这些区最开始的2个页面的类型是固定的，分别是：
  - `XDES`类型：全称是`extent descriptor`，用来登记本组256个区的属性，也就是说对于在`extent 256`区中的该类型页面存储的就是`extent 256` ~ `extent 511`这些区的属性，对于在`extent 512`区中的该类型页面存储的就是`extent 512` ~ `extent 767`这些区的属性。上边介绍的`FSP_HDR`类型的页面其实和`XDES`类型的页面的作用类似，只不过`FSP_HDR`类型的页面还会额外存储一些表空间的属性。
  - `IBUF_BITMAP`类型

**提出区和组的概念是为了尽量让链表中相邻的页物理位置也相邻，尽可能的减少随机IO，变成顺序IO，提高IO性能**

- 叶子节点和非叶子节点的区不同。一个索引会生成两个段，一个叶子节点段，一个非叶子节点段

考虑到对于存储记录较少的表分配完整的区很浪费空间，所以为某个段分配存储空间时，策略是

- 在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的。
- 当某个段已经占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间。

因此，段不能仅定义为是某些区的集合，更精确的应该是某些零散的页面以及一些完整的区的集合。

表空间是由若干个区组成的，每个区都对应一个`XDES Entry`的结构，直属于表空间的区对应的`XDES Entry`结构可以分成`FREE`、`FREE_FRAG`和`FULL_FRAG`这3个链表；每个段可以附属若干个区，每个段中的区对应的`XDES Entry`结构可以分成`FREE`、`NOT_FULL`和`FULL`这3个链表。每个链表都对应一个`List Base Node`的结构，这个结构里记录了链表的头、尾节点的位置以及该链表中包含的节点数。正是因为这些链表的存在，管理这些区才变成了一件so easy的事情。

### InnoDB的数据字典

MySQL除了保存着我们插入的用户数据之外，还需要保存许多额外的元数据

定义了一些内部系统表来记录这些元数据，放在系统表空间内，这些系统表也被称为数据字典

![](https://raw.githubusercontent.com/hattori7243/img/master/20210607105651.png)

这4个表的聚簇索引和二级索引对应的`B+树`位置，这个页面就是页号为`7`的页面，类型为`SYS`，记录了`Data Dictionary Header`，也就是数据字典的头部信息。除了这4个表的5个索引的根页面信息外，这个页号为`7`的页面还记录了整个InnoDB存储引擎的一些全局属性

# 单表访问方法

### 分类

- 通过主键或者唯一二级索引列与**常数的等值比较**来定位一条记录的速度很快，所以把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：`const`
  - 对于唯一二级索引来说，查询该列为`NULL`值的情况比较特殊，因为唯一二级索引并不限制NULL的数量
- 对某个普通二级索引与常数进行等值比较，因为普通二级索引并不限制索引列值的唯一性，所以可能找到多条记录，也就是执行查询的代价取决于等值匹配到的二级索引记录条数，如果匹配记录较少，回表代价还是比较低的。这样采用二级索引来执行查询的访问方法称为：`ref`
- 利用索引进行范围匹配的访问方法叫做`range`，包括聚簇索引和二级索引。
- 在联合索引中，如果查询的条件和需要返回查询结果的列都在联合索引中，就可以直接遍历联合索引的叶子节点进行判断即可，由于二级索引记录比聚簇索引小的多且不需要回表操作，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多。这种遍历二级索引的方式称为`index`

- 直接完整扫描聚簇索引，称为`all`

# 索引合并

Mysql在一般情况下执行一个查询最多会用到单个二级索引，但是特殊情况下也可能在一个查询中使用到多个二级索引，这种使用到多个索引来完成一次查询的执行方法称为`index merge`

1. Intersection合并（与逻辑）

某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集，比方说下边这个查询：

```
SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b';
```

此时，可以按照不同的搜索条件分别读取不同的二级索引，再对多个二级索引得到的主键值进行取交集，再进行回表操作。

也可以只根据之前说的，先读取key1的二级索引，根据得到的主键进行回表操作，再过滤key2的搜索条件。

虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是`顺序I/O`，而回表操作是`随机I/O`，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，当节省的因为`回表`而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低。

**根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，而通过`Intersection`索引合并后需要回表的记录数大大减少时才会使用`Intersection`索引合并**

可能会用到Intersection索引合并的情况（必要条件，不是充分条件）

- 二级索引列都是等值匹配，联合索引中每个列都是等值匹配的情况。这种情况取交集的记录会相对较少，所以需要进行回表操作的记录较少。
- 搜索条件中有主键的范围匹配的情况下也可以使用`Intersection`索引合并索引合并，原因是因为二级索引中的记录也是带有主键值的，而且在索引列值相同时，是按照主键来进行排序的。

2. Union合并（或逻辑）

可能使用Union索引合并的情况

- 二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。
- 主键列可以是范围匹配
- 使用`Intersection`索引合并的搜索条件

3. Sort-Union合并

`Union`索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到`Union`索引合并：

```
SELECT * FROM single_table WHERE key1 < 'a' OR key3 > 'z'
```

而这只所以不能使用Union合并的原因在，根据二级索引得到的记录并不是根据主键排好序的。因此，如果直接将两个根据二级索引得到的记录进行排序，剩下的操作的就和Union索引一样的。

P.S：为什么只有Sort-Union合并，而没有Sort-Intersection合并。Sort-Union的适用场景是单独根据搜索条件从某个二级索引中获取的记录数比较少，这样即使对这些二级索引记录按照主键值进行排序的成本也不会太高 而Intersection索引合并的适用场景是单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，合并后可以明显降低回表开销，但是如果加入Sort-Intersection后，就需要为大量的二级索引记录按照主键值进行排序，这个成本可能比回表查询都高了，所以也就没有引入Sort-Intersection

# 连接Join

在两表连接查询中，驱动表只需要访问一次，被驱动表可能被访问多次，取决于驱动表中查出的结果。

**内连接和外连接**

本质区别是，驱动表中的记录在被驱动表中没有匹配的记录，是否需要加入到结果中

- 内连接：驱动表中的记录在被驱动表中没有匹配的记录，不会加入到最后结果中
- 外连接：驱动表中的记录在被驱动表中没有匹配的记录，仍然会加入到最后结果中
  - 因此，根据驱动表的选取不同，有左外连接和右外连接，即选取左边还是右边的为驱动表

- ON语句的过滤条件，和where不同，`ON`子句是专门为外连接驱动表中的记录在被驱动表找不到匹配记录时应不应该把该记录加入结果集这个场景下提出的，所以如果把`ON`子句放到内连接中，`MySQL`会把它和`WHERE`子句一样对待
- **内连接和外连接的根本区别就是在驱动表中的记录不符合`ON`子句中的连接条件时不会把该记录加入到最后的结果集**
- 对于内连接来说，选取那个表作为驱动表没关系

## 连接的原理

- 嵌套循环连接（Nested-Loop Join）
- 使用索引加快连接速度
- 基于块的嵌套循环连接
  - 为了减少驱动表中的每条结果记录都需要去被驱动表中匹配一次，设置一个join buffer，将驱动表的结果记录多条放在buffer中，每次从被驱动表中拿一条记录出来时，可以和buffer中的多条记录比较，大大减少读被驱动表的次数，也减少了从磁盘到内存的IO次数

# Mysql基于成本的优化

对于同一条查询语句，可以有很多不同的执行方案。Mysql会选取成本最低的方案真正执行查询。而Mysql的查询执行成本主要有两方面：

- IO成本：即将索引从磁盘加载到内存中的成本
- CPU成本：读取以及检测记录是否对应搜索的条件、对结果进行排序的成本

对于`InnoDB`存储引擎来说，页是磁盘和内存之间交互的基本单位，规定读取一个页面花费的成本默认是`1.0`，读取以及检测一条记录是否符合搜索条件的成本默认是`0.2`。`1.0`、`0.2`这些数字称之为`成本常数`

Mysql执行语句的步骤：`MySQL`的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的`执行计划`，之后才会调用存储引擎提供的接口真正的执行查询

1. 根据搜索条件，找出所有可能使用的索引
2. 计算全表扫描的代价
3. 计算使用不同索引执行查询的代价
4. 对比各种执行方案的代价，找出成本最低的那一个

## InnoDB如何收集统计数据

两种统计数据，可以指定某些表的存储方式：

1. 永久性的统计数据：存储在硬盘上， 服务器重启后还在
2. 非永久性的统计数据：存储在内存中，服务器关闭就清除

### 基于磁盘的永久性统计数据

位于两个表中

- innodb_table_stats：存储了关于表的统计数据，一条记录对应一个表
  - 主键是数据库名+表名
  - 包括最后更新时间、记录的总条数、聚簇索引占用的页面数量、其他索引占用的页面数量
- Innodb_index_stats：存储了关于索引的统计数据，一条记录对应一个索引的一个统计项
  - 主键是数据库名+表名+索引名+统计项的名称
  - 包括最后更新时间、统计项的名称、统计项的值，为生成统计数据而采样的页面数量、描述等

#### 更新统计数据的方式

- 自动重新计算，可以控制。每个表都维护了一个变量，记录了对该表进行增删改的记录条数，如果变动的数量超过10%，且自动重新计算开关被打开，就会重新统计。过程是异步的
- 手动调用ANALYZE TABLE来更新统计信息，过程是同步的

### 基于内存的非永久性统计数据

最近版本的用的比较少

**innodb_stats_method决定着在统计某个索引列不重复值的数量时如何对待NULL值。**

# Mysql基于规则的优化

即将语句转化为可以比较高效执行的形式，也叫做`查询重写`

- 条件化简，即根据逻辑运算的性质化简

- 常量表检测

  - 对使用主键等值匹配或唯一二级索引等值匹配作为搜索条件来查询某个表的，会先对该条件进行查询，并将返回结果作为常量替换原来的条件继续后面的查询

- 在外连接查询中，指定的`WHERE`子句中包含被驱动表中的列不为`NULL`值的条件称之为`空值拒绝`。当外连接的where语句符合空值拒绝的情况时，外连接可以转化成内连接，然后查询优化器就可以通过评估连接顺序的成本，来选择进行查询。

  - 例如`SELECT * FROM t1 LEFT JOIN t2 ON t1.m1 = t2.m2 WHERE t2.n2 IS NOT NULL;`
  - `SELECT * FROM t1 INNER JOIN t2 ON t1.m1 = t2.m2 WHERE t2.m2 = 2;`
  - 这两种语句，先被where筛选了以后，即使on匹配不上，也不存在null来进行外连接了。所以等价于内连接

- 如果`IN`子查询符合转换为`semi-join`的条件，查询优化器会优先把该子查询转换为`semi-join`，然后再考虑下边5种执行半连接的策略中哪个成本最低：

  - Table pullout
  - DuplicateWeedout
  - LooseScan
  - Materialization
  - FirstMatch

  选择成本最低的那种执行策略来执行子查询。

- 如果`IN`子查询不符合转换为`semi-join`的条件，那么查询优化器会从下边两种策略中找出一种成本更低的方式执行子查询：

  - 先将子查询物化之后再执行查询
  - 执行`IN to EXISTS`转换。转化为exists后，可能能用上索引

# Mysql的执行计划Explain

`查询语句`在经过`查询优化器`各种优化后会生成一个`执行计划`，`EXPLAIN`·语句可以用来查看某个查询语句的具体执行计划。

`EXPLAIN`语句输出的每条记录对应的是对一个**单表**的访问方法。

在连接中，出现在前面的记录是驱动表，出现在后面的是被驱动表。例如下面这个内连接，查询结果就表示是以s1作为驱动表，s2作为被驱动表。

![](https://raw.githubusercontent.com/hattori7243/img/master/20210616104834.png)

如果一个查询涉及多个`SELECT`关键字，每个`SELECT`关键字都会对应一个唯一的`id`值。

查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询。因此，通过EXPLAIN我们也可以看到是否有进行重写等。

### select_type

查询的`select_type`属性，就知道了这个查询在整个查询语句中扮演了一个什么角色

- `SIMPLE`：查询语句中不包含UNION或者子查询的就是SIMPLE类型，包括连接查询
- `PRIMARY`：对于包含UNION、UNION ALL或者子查询的大查询来说，是由几个小查询组成的，其中最左边那个查询就是主查询PRIMARY。
- `UNION`：对于包含`UNION`或者`UNION ALL`的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的`select_type`值就是`UNION`
- `UNION RESULT`：MySQL`选择使用临时表来完成`UNION`查询的去重工作，针对该临时表的查询的`select_type`就是`UNION RESULT
  - 如`SELECT * FROM s1 UNION SELECT * FROM s2;`中的第一个SELECT是PRIMARY，第二个是UNION
  - ![](https://raw.githubusercontent.com/hattori7243/img/master/20210616105655.png)
- `SUBQUERY`：如果包含子查询的查询语句不能够转为对应的`semi-join`的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个`SELECT`关键字代表的那个查询的`select_type`就是`SUBQUERY`。
  - ![](https://raw.githubusercontent.com/hattori7243/img/master/20210616105751.png)
- `DEPENDENT SUBQUERY`：和SUBQUERY类似，但是子查询是相关子查询。
- `DERIVED`：对于采用物化的方式执行的包含派生表的查询，该派生表对应的子查询的`select_type`就是`DERIVED`
- `MATERIALIZED`：当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询

---

在`EXPLAIN`单词和真正的查询语句中间加上`FORMAT=JSON`可以得到一个json格式的执行计划，里面有该计划花费的成本。

可以使用`SHOW WARNINGS`语句查看与这个查询的执行计划有关的一些扩展信息

## Optimizer trace

在`MySQL 5.6`以及之后的版本中，设计`MySQL`的大叔贴心的为这部分小伙伴提出了一个`optimizer trace`的功能，这个功能可以让我们方便的查看优化器生成执行计划的整个过程，这个功能的开启与关闭由系统变量`optimizer_trace`决定，默认是关闭的

完整的使用`optimizer trace`功能的步骤总结如下：

```
# 1. 打开optimizer trace功能 (默认情况下它是关闭的):
SET optimizer_trace="enabled=on";

# 2. 这里输入你自己的查询语句
SELECT ...; 

# 3. 从OPTIMIZER_TRACE表中查看上一个查询的优化过程
SELECT * FROM information_schema.OPTIMIZER_TRACE;

# 4. 可能你还要观察其他语句执行的优化过程，重复上边的第2、3步
...

# 5. 当你停止查看语句的优化过程时，把optimizer trace功能关闭
SET optimizer_trace="enabled=off";
```

# InnoDB的Buffer Pool

为了避免频繁的磁盘IO，`MySQL`服务器在启动的时候就向操作系统申请了一片连续的内存，他们给这片内存起了个名，叫做`Buffer Pool`（中文名是`缓冲池`），默认大小是128M，可以通过改`innodb_buffer_pool_size`来更改，单位是字节。

`Buffer Pool`中默认的缓存页大小和在磁盘上默认的页大小是一样的，都是`16KB`。

每一个缓存页都创建了一些所谓的`控制信息`，这些控制信息包括该页所属的表空间编号、页号、缓存页在`Buffer Pool`中的地址、链表节点信息、一些锁信息以及`LSN`。

每个控制块大约占用缓存页大小的`5%`

控制信息占用的一块内存称为一个`控制块`吧，控制块和缓存页是一一对应的，它们都被存放到 Buffer Pool 中，其中控制块被存放到 Buffer Pool 的前边，缓存页被存放到 Buffer Pool 后边，所以整个`Buffer Pool`对应的内存空间看起来就是这样的：

![](https://raw.githubusercontent.com/hattori7243/img/master/20210616145855.png)

### free链表的管理——管理如何分配

用于管理哪些缓存页被使用或者空闲，把所有空闲的缓存页对应的控制块作为一个节点放到一个链表中，这个链表也可以被称作`free链表`（或者说空闲链表）。

<img src="https://raw.githubusercontent.com/hattori7243/img/master/20210616150240.png" style="zoom:150%;" />



为了便于管理，基节点占用的内存空间并不包括在为缓冲池申请的一大片连续内存空间中。基节点几乎都是单独申请的一块40字节大小的内存空间。

### 缓存页的哈希处理——检查是否已经缓存

根据`表空间号 + 页号`来定位一个页的，也就相当于`表空间号 + 页号`是一个`key`，`缓存页`就是对应的`value`。

因此，可以用`表空间号 + 页号`作为`key`，`缓存页`作为`value`创建一个哈希表，在需要访问某个页的数据时，先从哈希表中根据`表空间号 + 页号`看看有没有对应的缓存页，如果有，直接使用该缓存页就好，如果没有，那就从`free链表`中选一个空闲的缓存页，然后把磁盘中对应的页加载到该缓存页的位置。

### flush链表的管理——记录哪些页修改

为了避免每次对缓存页进行修改时都需要同步到磁盘上的频繁IO，创建一个存储脏页的链表，凡是修改过的缓存页对应的控制块都会作为一个节点加入到一个链表中，因为这个链表节点对应的缓存页都是需要被刷新到磁盘上的，所以也叫`flush链表`。链表的构造和`free链表`差不多

刷新的时机：

1. 从`LRU链表`的冷数据中刷新一部分页面到磁盘
   - 后台线程会定时从`LRU链表`尾部开始扫描一些页面，发现脏页会把它们刷新到磁盘。这种刷新页面的方式被称之为`BUF_FLUSH_LRU`。
2. 从`flush链表`中刷新一部分页面到磁盘：`BUF_FLUSH_LIST`
3. 有时候后台线程刷新脏页的进度比较慢，导致用户线程在准备加载一个磁盘页到`Buffer Pool`时没有可用的缓存页，这时就会尝试看看`LRU链表`尾部有没有可以直接释放掉的未修改页面，如果没有的话会不得不将`LRU链表`尾部的一个脏页同步刷新到磁盘（和磁盘交互是很慢的，这会降低处理用户请求的速度）。这种刷新单个页面到磁盘中的刷新方式被称之为`BUF_FLUSH_SINGLE_PAGE`。
4. 有时候系统特别繁忙时，也可能出现用户线程批量的从`flush链表`中刷新脏页的情况，但是在处理用户请求过程中去刷新脏页会**严重降低处理速度**

### LRU链表——记录更新情况，为换入换出提供依据

需要缓存的页占用的内存大小超过了`Buffer Pool`大小，需要把某些旧的缓存页从`Buffer Pool`中移除，然后再把新的页放进来。

- 简单的LRU链表

  - 只要我们使用到某个缓存页，就把该缓存页调整到`LRU链表`的头部，这样`LRU链表`尾部就是最近最少使用的缓存页。 所以当`Buffer Pool`中的空闲缓存页使用完时，到`LRU链表`的尾部找缓存页淘汰

- 划分区域的LRU链表

  - 由于存在1.加载到Buffer Pool中的页不一定被用到。2.非常多的使用频率偏低的页被同时加载到`Buffer Pool`时，可能会把那些使用频率非常高的页从`Buffer Pool`中淘汰掉
  - 因此，为了避免预读情况和全表扫描情况，大量涌入的页面将热点页面刷走，将链表划分为两个区域，young区域和old区域

  ![](https://raw.githubusercontent.com/hattori7243/img/master/20210616151405.png)

  - 在初次被加载进来时，只会放到old区域的前面。因此，如果预读进来的部分并没有被访问的话，也并不会影响前面频繁访问的数据。
  - 而针对全表扫描时大量涌入的页面，因为其执行频率非常低，某个处在`old`区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该页面就不会被从old区域移动到young区域的头部。

- 其他优化：比如对young热点数据，并不每次移动到最前面。而是当位于young尾部时，访问才移到头部。为了避免频繁的节点移动操作。

### 多个Buffer Pool实例——提高并发性

访问`Buffer Pool`中的各种链表都需要加锁处理啥的，在`Buffer Pool`特别大而且多线程并发访问特别高的情况下，单一的`Buffer Pool`可能会影响请求的处理速度。

所以在`Buffer Pool`特别大的时候，我们可以把它们拆分成若干个小的`Buffer Pool`，每个`Buffer Pool`都称为一个`实例`，它们都是独立的，独立的去申请内存空间，独立的管理各种链表等

可以在服务器启动的时候通过设置`innodb_buffer_pool_instances`的值来修改`Buffer Pool`实例的个数

```
[server]
innodb_buffer_pool_instances = 2
```

当`innodb_buffer_pool_size`的值小于1G的时候设置多个实例是无效的，InnoDB会默认为1。而我们鼓励在`Buffer Pool`大于或等于1G的时候设置多个`Buffer Pool`实例。

可以用下边的命令查看Buffer Pool的状态信息：

```
SHOW ENGINE INNODB STATUS\G
```

# 事务

四个特性：`A C I D`

- 原子性 `Atomicity`：要么全做、要么全不做，不可分割
- 一致性 `Consistency`：数据库中的数据全部符合现实世界中的约束
- 隔离性 `Isolation`：保证其它的状态转换不会影响到本次状态转换
- 持久性 `Durability`：当现实世界的一个状态转换完成后，这个转换的结果将永久的保留

满足原子性、一致性、隔离性、持久性的一个或者多个数据库操作称之为一个**`事务`**

**事务的状态**

![](https://raw.githubusercontent.com/hattori7243/img/master/20210617155450.png)

## 事务的语法

- 开启事务：`BEGIN [WORK]`或者`START TRANSACTION`

`START TRANSACTION`后面可以跟上修饰符，`READ ONLY`代表只读，`READ WRITE`代表只写，`WITH CONSISTENT SNAPSHOT`启动一致性读。默认访问模式是读写模式，既可以读也可以写

- 提交事务：`COMMIT [WORK]`

- 手动回滚事务：在还没有commit的时候，发现错误了，可以用`ROLLBACK`来手动回滚事务。当事务执行过程中出错时，会自动回滚。

Mysql中并不是所有存储引擎都支持事务，只有`InnoDB和NDB`支持。

如果某个事务中包含了修改使用不支持事务的存储引擎的表，那么对该使用不支持事务的存储引擎的表所做的修改将无法进行回滚

Mysql中的系统变量autocommit=On默认每条语句都是一个独立的事务

### 隐式的提交

一般不会自动提交，会等待我们输入commit。

但是当输入一些特殊的语句之后会导致事务被偷偷提交。包括：

- 定义或修改数据库对象的数据定义语言（Data definition language，缩写为：`DDL`）
- 隐式使用或修改`mysql`数据库中的表，例如增加删除用户等
- 事务控制或关于锁定的语句，比如一个事物还没commit又开始了一个新的事务
- 加载数据`load data`
- 关于`MySQL`复制的一些语句
- 其它的一些语句

### 保存点

为了避免在事务过程中出错必须回到最初的地方，设置了保存点

定义保存点

```
SAVEPOINT 保存点名称;
```

回滚到某个保存点

```
ROOLEBACK [WORK] TO [SAVEPOINT] 保存点名称;
```

## 隔离级别

为了解决以下几个问题，提出了隔离级别的概念：

- 脏读：即读到了最终不一定存在的数据。例如别的事务更新了，但是后面有可能回滚。
- 可重复读：在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据**更新（UPDATE）**操作。是我们想要做到的。
- 不可重复读：对比可重复读，不可重复读指在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据**更新（UPDATE）**操作。是我们想要解决的问题
- 幻读：幻读是针对数据**插入（INSERT）**操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉，这就叫幻读。

**四个隔离级别**

- 1. 读未提交`(READ UNCOMMITTED)`

不进行任何处理，无法解决任何问题

- 2. 读提交`(READ COMMITED)`

读提交就是一个事务**只能读到其他事务已经提交过的数据**，也就是其他事务调用 commit 命令之后的数据

这个解决了脏读的问题，因为读到的数据必然是提交过的，不会回滚。

但是无法解决不可重复读的问题，因为B在事务过程中，A事务可能对数据进行了更改，所以导致B在事务过程中，读到的数据不一致。

- 3. 可重复读`(REPEATABLE READ)`

可重复读是在事务开始的时候生成一个当前事务全局性的快照，而读提交则是每次执行语句的时候都重新生成一次快照。

并发写问题，通过加行锁来实现。

Mysql在可重复读下解决了幻读问题，通过间隙锁。因为对表中已有的数据加行锁并不能避免新数据行的加入。所以需要对范围加锁。这样新加的记录如果在这个范围内，就有可能发生幻读，就等待。

行锁和间隙锁合并，叫做Next-key锁

- 4. 串行化`(SERIALIZABLE)`

将事务的执行变为顺序执行，相当于单线程，但是执行效果太差了。

读的时候加共享锁，写的时候加排他锁。

由上往下隔离级别逐渐增强，性能逐渐变差。

![](https://raw.githubusercontent.com/hattori7243/img/master/20210617161537.png)

**Mysql默认采用可重复读级别**

事务隔离是依靠锁来实现的。最低级别的读未提交是不加锁的，所以性能最好，但也无法解决之前提到的任何一个问题

### MVCC

全称Multi-Version Concurrency Control，多版本并发控制

在多个事务进行更改时，一个记录可能会有一个版本链。

![image-20210628155518567](/Users/zhangshuyu/Documents/MyNote/pic/mysql掘金小册学习/image-20210628155518567.png)

而在不同隔离界别下，当前事务可见的范围是不同的。

因此，提出ReadView概念，主要包括

- m_ids：表示生成ReadView时活跃的事务列表，事务id
- min_trx_id：m_ids中最小的事务id
- max_trx_id：应该分配给下一个事务的id
- creator_trx_id：生成此ReadView的事务id

因此，通过事务id来判断究竟能访问到哪一个版本。

**在`MySQL`中，`READ COMMITTED`和`REPEATABLE READ`隔离级别的的一个非常大的区别就是它们生成ReadView的时机不同**

- 在Read COMMITTED中是在每一次读取数据前都生成一个ReadView。所以只要提交了就能被读到。所以在事务执行过程中，可能会读到不同的值哪怕自己没修改。
- 在REPEATABLE READ中，只会在第一次读取数据时生成一个READVIEW，因此在该事务执行过程中，其他事务提交的变化，是读不到的。因此可以保证在此事务执行过程中的可重复读

# 日志

## redo日志

为了保障持久性，但是对页面的更改又是对内存中缓存的更改，如果每次更改都需要写回磁盘的话，那缓存的意义就没了。

因为可能修改的数据相对于一个数据页来说很小，并且由于一条语句可能修改多个页面，所以随机IO也很慢。

因此，为了保障持久性的同时，又减少写回磁盘的io，我们将还没写回磁盘的更改操作记录到一个日志里面，这样当崩溃重启时，我们只需要按照记录的日志重新做一遍操作即可恢复到最新的状态。

而这样的日志就被称为redo日志。

用redo日志来代替刷新缓存回磁盘的好处有：

- redo日志的占用空间远远小于数据页
- redo日志是顺序写入磁盘的，避免了随机IO

---

### redo日志格式

![](https://raw.githubusercontent.com/hattori7243/img/master/20210622184530.png)

- type：该条redo日志的类型
  - 物理日志主要是记录在页面的某个偏移量写入了多少字节的数据（1，2，4，8，一串）
  - 逻辑日志记录的当前的状态，崩溃恢复时，用当前状态重新调用一遍更新的函数即可，避免过多条的redo日志
- space ID：表空间ID
- page number：页号
- data：该条redo日志的具体内容

---

以组的形式写入redo日志，是为了保证一系列操作的原子性，避免中途停顿的话，造成数据不对。

通过在系列操作的最后加入一个特殊的redo日志来做到，这个特殊的redo日志只有一个特殊的type语句。

这样对页面的一次原子访问成为一个**Mini-Transaction**，简称mtr。在进行崩溃恢复时这一组redo日志作为不可分割的一个整体

需要和事务的概念区分，关系如下

<img src="https://raw.githubusercontent.com/hattori7243/img/master/20210622185824.png" style="zoom:67%;" />

---

为了区分，redo日志被保存在512字节大小的页中，并且将这个页称为block。

redo日志也有一个缓冲区，并不是一直进行磁盘IO。刷新的情况有：

- 缓冲区空间不足时
- 事务提交时，保证持久性
- 后台线程定时刷新，大约一秒一次
- 正常关闭服务器时
- save checkpoint时

刷新到mysql数据目录下的`ib_logfile0`和`ib_logfile1`中

### Log Sequence Number

为了记录已经写入的redo日志量，设计了这个`Log Sequence Number`的全局变量，即日志序列号

lsn值越小，代表该redo日志产生的最早

### flushed_to_disk_lsn

标记当前log buffer中已经有哪些日志被刷新到磁盘中

和lsn一起就可以确定还有哪些日志还没刷新到磁盘中

### checkpoint

为了避免redo日志单调增长越来越大，我们需要循环使用redo日志文件组中的文件。

对redo日志来说，如果该日志记录的修改脏页已经刷新到了磁盘，那么该redo日志就没有存在的必要了。

为了判断这种情况，就设置一个checkpoint_lsn来代表当前系统中可以被覆盖的日志总量

## undo日志

在事务的原子性中，当事务执行发生错误或者使用ROLLBACK语句回滚的时候，会导致事务执行到一半就结束。但是此时事务执行过程中已经对数据库进行修改，为了保证原子性，我们需要还原回开始的样子即回滚。

为了做到回滚而记录的日志称为撤销日志，即undo日志

**事务id**

如果某个事务执行过程中对某个表执行了增、删、改操作，那么`InnoDB`存储引擎就会给它分配一个独一无二的`事务id`

也就是说，如果是对于只读事务，只有他第一次对用户创建的临时表（select语句创建的不算）进行增删改的操作才会分配事务id，否则不分配

### 日志格式

一般在增删改一条记录时，对应一条undo日志

一个事务在执行过程中，会增删改更新多条记录，因此需要记录多条undo日志

#### 增加记录

其实就是记录下来增加记录的表和主键值，回滚直接根据这个找到然后删除即可

![](https://raw.githubusercontent.com/hattori7243/img/master/20210623163358.png)

#### 删除记录

在事务中，删除时并没有真正的删除，只是将对应记录的delete_mask的标志设置为1，代表删除了。但是实际并没有真正删除，还是在正常记录链表中。

当事务提交以后，才会有专门的线程来将该记录从正常记录链表中移动到垃圾链表中。

需要要记录下主键，如果回滚来定位恢复删除标记位。

记录其他索引列的信息。用来事务提交后更新索引元信息。

其次，该记录原先的trx_id和roll_pointer也要保存下来

![](https://raw.githubusercontent.com/hattori7243/img/master/20210623164200.png)

#### 更新记录

- 不更新主键时
  - 如果每一个更新后的列都和更新前一样，就地更新
  - 否则，删除旧记录（真正删除），插入新纪录。
- 更新主键时
  - 将旧记录delete mark，事务提交以后才真正删除
    - 是因为别的事务也可能访问这条记录，如果真正删除加入到垃圾链表中，别的事务就访问不到了
  - 按更新的列插入一条新纪录
  - 这种情况下，undo日志由一条delete日志和一条insert日志组成

### FIL_PAGE_UNDO_LOG页面

专门用来存储undo日志

![image-20210628111139944](/Users/zhangshuyu/Documents/MyNote/pic/mysql掘金小册学习/image-20210628111139944.png)

![image-20210628111212987](/Users/zhangshuyu/Documents/MyNote/pic/mysql掘金小册学习/image-20210628111212987.png)

- `TRX_UNDO_PAGE_TYPE`：本页面准备存储什么种类的`undo日志`。`
  - 一个页面存储的undo日志的类型都是相同的

- `TRX_UNDO_PAGE_NODE`：代表一个`List Node`结构（链表的普通节点，我们上边刚说的）。
- 因此，一个事务执行过程中，可能需要两个Undo页面的链表，一个insert undo链表，一个update undo链表

![image-20210628111822474](/Users/zhangshuyu/Documents/MyNote/pic/mysql掘金小册学习/image-20210628111822474.png)

再加上对普通表的改动和对临时表的改动产生的undo日志要分别记录，所以最多会有**四个**链表

并不是在事务一开始就会为这个事务分配这4个链表，按需分配，啥时候需要啥时候再分配，不需要就不分配。

### 重用Undo页面

事务提交后某些情况下，该事务的Undo页面链表是可以重用的

- 该链表中只包含一个Undo页面
- 该`Undo页面`已经使用的空间小于整个页面空间的3/4。

# 锁

## 分类

锁分为**共享锁**(Share，**S锁**)，**独占锁**(Exclusive，**X锁**)。

InnoDB中锁的粒度，分为行锁和表锁。顾名思义，就是锁的一行（一条记录），还是锁住一张表

- 意向锁

当我们想加表锁的时候，需要判断表内是否有加行锁。但是遍历一遍肯定是不现实的。

因此就设计了IX、IS意向表锁，当加行锁时会相应的加一个这样的表锁。

这样给表加锁的时候就可以很快判断。

### 表锁

#### 表级S锁、X锁

一般InnoDB中提供的表锁很少被用到。

在执行DDL语句时，一般都是通过在server层使用元数据锁来实现，独立于存储引擎。

#### 表级IS、IX锁

用于在为记录加锁时，先给表级别加锁表明当前表有记录加了行锁，避免用遍历的形式判断。

#### Auto-Inc锁

某个列有AUTO_INCREMENT属性时，系统会自动赋值。

此时就有用到此锁

在执行插入语句时就在表级别加一个`AUTO-INC`锁，然后为每条待插入记录的`AUTO_INCREMENT`修饰的列分配递增的值，在该语句执行结束后，再把`AUTO-INC`锁释放掉。

此时其他事务的插入语句都要被阻塞

### 行锁

#### Record Locks

记录锁，**仅仅锁住一条记录**

也分为S和X锁

#### Gap Locks

区间锁，给区间加锁。

为了解决幻读问题。

给一条记录加了`gap锁`只是不允许其他事务往这条记录前边的间隙插入新记录

#### Next-Key Locks

即将Record Locks和Gap Locks结合，即锁住记录又锁住区间。

起到既能保护该条记录，又能阻止别的事务将新纪录插入被保护记录前边的间隙

#### Insert Intention Locks

插入意向锁，即当插入时发现有gap锁，就生成一个锁代表想在某个间隙插入新纪录

#### 隐式锁

当一个事务插入一条记录。另一个事务要读取该记录的情况下，通过MVCC的事务id和快照会进行判断，如果可以访问，是会帮助该事务加锁然后自己进入等待状态的。

也就是插入新纪录的事务并不显示加锁，但是由于事务id，最后可能会导致别的事务为他生成锁。

## 锁的内存结构

![image-20210628201609509](/Users/zhangshuyu/Documents/MyNote/pic/mysql掘金小册学习/image-20210628201609509.png)

- 事务信息：记录哪个事务生成的锁结构
- 索引信息：记录加锁的记录属于哪个索引

- 表锁/行锁信息
  - 表锁记录对哪个表加的锁
  - 行锁记录行所在表空间、页号、位图的长度来记录是对哪个行加锁。位图位于最后一堆比特位处
- type_mode：记录锁的模式、类型、具体类型、是否正在等待
  - 模式：IX IS S X AUTO-INC
  - 类型：表锁 行锁
  - 具体类型：Next-key、Gap、Record、Insert Intention
  - is_waiting 正在等待

# 数据库的设计范式

## 第一范式（1NF）

- 如果一个关系模式R的所有属性都是**不可分**的基本数据项，则R∈1NF
- 1NF强调的是**列的原子性**，即列不能够再分

如学生（学号，姓名，性别，出生年月日），如果认为最后一列还可以再分成（出生年，出生月，出生日），它就不是一范式了

## 第二范式（2NF）

- 关系模式R∈1NF，并且每一个非主属性都完全函数依赖于R的主键，则R∈2NF
- 2NF 在1NF 的基础上要求**非主键字段必须完全函数依赖于主键**，不能只依赖于主键的一部分
- **所以只有一个主键的表如何符合第一范式，必然也符合第二范式**

如表：学号、课程号、姓名、成绩          
这个表明显说明了两个事务:学生信息, 课程信息; 主键是学号和课程号，姓名只依赖于学号，不满足 2NF   

## 第三范式（3NF）

- 3NF 要求在 2NF 的基础上，任何非主属性不依赖于其他非主属性，即**在2NF的基础上消除传递依赖**    

如表: 学号, 姓名, 年龄, 学院名称, 学院电话   
因为存在依赖传递: (学号)  → (学院名称) → (学院电话)。即学院电话可以由学院名称完全确定

### 1.4.4 BCNF范式  

- BCNF范式是对 3NF 的改进，对3NF关系进行投影，将消除原关系中主属性对键的部分与传递依赖
- 关系模式R<U，F>∈1NF。若函数依赖集合F中的所有函数依赖X→Y（Y不包含于X）的左部都包含R的任一候选键，则R∈BCNF

![image-20210628204129960](/Users/zhangshuyu/Documents/MyNote/pic/mysql掘金小册学习/image-20210628204129960.png)

例如上面这个表，码是<仓库名，物品名>和<管理员，物品名>。主属性：仓库名，管理员，物品名，非主属性：数量。

可以看到，主属性中的仓库名是依赖与<管理员，物品名>的。因此，消除主属性对码的依赖。

将表拆分为仓库名-管理员和仓库名-物品名-数量。